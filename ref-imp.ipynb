{"cells":[{"cell_type":"markdown","metadata":{},"source":["<table align=\"left\">\n","  <td>\n","    <a href=\"https://colab.research.google.com/github.com/phonchi/Fundamental-tools-for-data-science/blob/main/ref-imp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/phonchi/Fundamental-tools-for-data-science/blob/main/ref-imp.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n","  </td>\n","  <td style=\"text-align: center\">\n","    <a href=\"https://github.com/phonchi/Fundamental-tools-for-data-science/blob/main/ref-imp.ipynb\">\n","      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n","    </a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"ZB0uE-rI1FIl"},"source":["First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-05T04:08:42.098227Z","iopub.status.busy":"2024-08-05T04:08:42.097607Z","iopub.status.idle":"2024-08-05T04:08:56.391508Z","shell.execute_reply":"2024-08-05T04:08:56.390652Z","shell.execute_reply.started":"2024-08-05T04:08:42.098195Z"},"executionInfo":{"elapsed":3106,"status":"ok","timestamp":1647662906415,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"},"user_tz":-480},"id":"Jc9dG1NU1FIm","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-05 04:08:45.161965: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-05 04:08:45.162076: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-05 04:08:45.287154: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["# Python ≥3.5 is required\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","# Is this notebook running on Colab or Kaggle?\n","IS_COLAB = \"google.colab\" in sys.modules\n","IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n","\n","# Scikit-Learn ≥0.20 is required\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","\n","# TensorFlow ≥2.0 is required\n","import tensorflow as tf\n","from tensorflow import keras\n","assert tf.__version__ >= \"2.0\"\n","\n","version_fn = getattr(tf.keras, \"version\", None)\n","if version_fn and version_fn().startswith(\"3.\"):\n","    import tf_keras as keras\n","else:\n","    keras = tf.keras\n","\n","if not tf.config.list_physical_devices('GPU'):\n","    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n","    if IS_COLAB:\n","        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n","    if IS_KAGGLE:\n","        print(\"Go to Settings > Accelerator and select GPU.\")\n","\n","# Common imports\n","import numpy as np\n","import os\n","import pandas as pd\n","\n","# to make this notebook's output stable across runs\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# To plot pretty figures\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)\n","\n","# Where to save the figures\n","PROJECT_ROOT_DIR = \".\"\n","CHAPTER_ID = \"cnn\"\n","IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n","os.makedirs(IMAGES_PATH, exist_ok=True)\n","\n","def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n","    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n","    print(\"Saving figure\", fig_id)\n","    if tight_layout:\n","        plt.tight_layout()\n","    plt.savefig(path, format=fig_extension, dpi=resolution)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-05T04:08:56.394474Z","iopub.status.busy":"2024-08-05T04:08:56.393401Z","iopub.status.idle":"2024-08-05T04:08:58.688682Z","shell.execute_reply":"2024-08-05T04:08:58.687932Z","shell.execute_reply.started":"2024-08-05T04:08:56.394432Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 27785 images belonging to 800 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n","\n","IMAGE_WIDTH=224\n","IMAGE_HEIGHT=224\n","IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n","IMAGE_CHANNELS=1\n","\n","batch_size=64\n","\n","\n","train_datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    rescale=1./255,\n","    shear_range=0.1,\n","    zoom_range=0.2,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    validation_split=0.2\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","        \"../input/data-science-capstone-project-spring-2022/training_data/training_data\",\n","    target_size=IMAGE_SIZE,\n","    batch_size=batch_size,\n","    class_mode='sparse',\n","    subset='training',\n","    color_mode='grayscale'\n",")"]},{"cell_type":"markdown","metadata":{"id":"nwDbg-7y1FIo"},"source":["A couple utility functions to plot grayscale and RGB images:"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-05T04:08:58.690096Z","iopub.status.busy":"2024-08-05T04:08:58.689815Z","iopub.status.idle":"2024-08-05T04:08:58.695262Z","shell.execute_reply":"2024-08-05T04:08:58.694313Z","shell.execute_reply.started":"2024-08-05T04:08:58.690073Z"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1647662919883,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"},"user_tz":-480},"id":"PvCU2Ic41FIo","trusted":true},"outputs":[],"source":["def plot_image(image):\n","    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n","    plt.axis(\"off\")\n","\n","def plot_color_image(image):\n","    plt.imshow(image, interpolation=\"nearest\")\n","    plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{"id":"sxW4W5wuk93b"},"source":["## Data preprocessing\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-05T04:08:58.697068Z","iopub.status.busy":"2024-08-05T04:08:58.696789Z","iopub.status.idle":"2024-08-05T04:09:12.421452Z","shell.execute_reply":"2024-08-05T04:09:12.420561Z","shell.execute_reply.started":"2024-08-05T04:08:58.697045Z"},"executionInfo":{"elapsed":2835,"status":"ok","timestamp":1647674555438,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"},"user_tz":-480},"id":"mflCzFpBloc8","outputId":"b2cc2ca2-e04f-4c15-b729-cb1e3ab48417","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 34428 files belonging to 800 classes.\n","Using 27543 files for training.\n","Found 34428 files belonging to 800 classes.\n","Using 6885 files for validation.\n"]}],"source":["from tensorflow.keras.utils import image_dataset_from_directory\n","\n","train_dataset = image_dataset_from_directory(\n","    \"../input/data-science-capstone-project-spring-2022/training_data/training_data\",\n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=1337,\n","    image_size=(50, 50),\n","    batch_size=32)\n","validation_dataset = image_dataset_from_directory(\n","    \"../input/data-science-capstone-project-spring-2022/training_data/training_data\",\n","    validation_split=0.2,\n","    seed=1337,\n","    subset=\"validation\",\n","    image_size=(50, 50),\n","    batch_size=32)"]},{"cell_type":"markdown","metadata":{"id":"HzNJXxA-ml9G"},"source":["Let’s look at the output of one of these Dataset objects: it yields batches of `180 × 180` RGB images (shape `(32, 180, 180, 3)`) and integer labels (shape `(32,)`). There are 32 samples in each batch (the batch size)."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-05T04:09:12.423843Z","iopub.status.busy":"2024-08-05T04:09:12.423205Z","iopub.status.idle":"2024-08-05T04:09:12.494129Z","shell.execute_reply":"2024-08-05T04:09:12.493256Z","shell.execute_reply.started":"2024-08-05T04:09:12.423809Z"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1647663870092,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"},"user_tz":-480},"id":"3nVxEzWMmsXA","outputId":"c8137c39-762b-46ae-8d68-e1434e8ea5cd","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data batch shape: (32, 50, 50, 3)\n","labels batch shape: (32,)\n"]}],"source":["for data_batch, labels_batch in train_dataset:\n","    print(\"data batch shape:\", data_batch.shape)\n","    print(\"labels batch shape:\", labels_batch.shape)\n","    break"]},{"cell_type":"markdown","metadata":{"id":"iCoc8y_GtY3I"},"source":["## Leveraging a pretrained model"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-05T04:09:26.945403Z","iopub.status.busy":"2024-08-05T04:09:26.944808Z","iopub.status.idle":"2024-08-05T04:09:26.957600Z","shell.execute_reply":"2024-08-05T04:09:26.956637Z","shell.execute_reply.started":"2024-08-05T04:09:26.945373Z"},"trusted":true},"outputs":[],"source":["def get_hub_url_and_isize(model_name, ckpt_type, hub_type):\n","  if ckpt_type == '1k':\n","    ckpt_type = ''  # json doesn't support empty string\n","  else:\n","    ckpt_type = '-' + ckpt_type  # add '-' as prefix\n","  \n","  hub_url_map = {\n","    'efficientnetv2-b0': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0/{hub_type}',\n","    'efficientnetv2-b1': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1/{hub_type}',\n","    'efficientnetv2-b2': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2/{hub_type}',\n","    'efficientnetv2-b3': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3/{hub_type}',\n","    'efficientnetv2-s':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s/{hub_type}',\n","    'efficientnetv2-m':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m/{hub_type}',\n","    'efficientnetv2-l':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l/{hub_type}',\n","\n","    'efficientnetv2-b0-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0-21k/{hub_type}',\n","    'efficientnetv2-b1-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1-21k/{hub_type}',\n","    'efficientnetv2-b2-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2-21k/{hub_type}',\n","    'efficientnetv2-b3-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3-21k/{hub_type}',\n","    'efficientnetv2-s-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k/{hub_type}',\n","    'efficientnetv2-m-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k/{hub_type}',\n","    'efficientnetv2-l-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k/{hub_type}',\n","    'efficientnetv2-xl-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-xl-21k/{hub_type}',\n","\n","    'efficientnetv2-b0-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0-21k-ft1k/{hub_type}',\n","    'efficientnetv2-b1-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1-21k-ft1k/{hub_type}',\n","    'efficientnetv2-b2-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2-21k-ft1k/{hub_type}',\n","    'efficientnetv2-b3-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3-21k-ft1k/{hub_type}',\n","    'efficientnetv2-s-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k-ft1k/{hub_type}',\n","    'efficientnetv2-m-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k-ft1k/{hub_type}',\n","    'efficientnetv2-l-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k-ft1k/{hub_type}',\n","    'efficientnetv2-xl-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-xl-21k-ft1k/{hub_type}',\n","      \n","    # efficientnetv1\n","    'efficientnet_b0': f'https://tfhub.dev/tensorflow/efficientnet/b0/{hub_type}/1',\n","    'efficientnet_b1': f'https://tfhub.dev/tensorflow/efficientnet/b1/{hub_type}/1',\n","    'efficientnet_b2': f'https://tfhub.dev/tensorflow/efficientnet/b2/{hub_type}/1',\n","    'efficientnet_b3': f'https://tfhub.dev/tensorflow/efficientnet/b3/{hub_type}/1',\n","    'efficientnet_b4': f'https://tfhub.dev/tensorflow/efficientnet/b4/{hub_type}/1',\n","    'efficientnet_b5': f'https://tfhub.dev/tensorflow/efficientnet/b5/{hub_type}/1',\n","    'efficientnet_b6': f'https://tfhub.dev/tensorflow/efficientnet/b6/{hub_type}/1',\n","    'efficientnet_b7': f'https://tfhub.dev/tensorflow/efficientnet/b7/{hub_type}/1',\n","  }\n","  \n","  image_size_map = {\n","    'efficientnetv2-b0': 224,\n","    'efficientnetv2-b1': 240,\n","    'efficientnetv2-b2': 260,\n","    'efficientnetv2-b3': 300,\n","    'efficientnetv2-s':  384,\n","    'efficientnetv2-m':  480,\n","    'efficientnetv2-l':  480,\n","    'efficientnetv2-xl':  512,\n","  \n","    'efficientnet_b0': 224,\n","    'efficientnet_b1': 240,\n","    'efficientnet_b2': 260,\n","    'efficientnet_b3': 300,\n","    'efficientnet_b4': 380,\n","    'efficientnet_b5': 456,\n","    'efficientnet_b6': 528,\n","    'efficientnet_b7': 600,\n","  }\n","  \n","  hub_url = hub_url_map.get(model_name + ckpt_type)\n","  image_size = image_size_map.get(model_name, 224)\n","  return hub_url, image_size"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-05T04:10:48.806660Z","iopub.status.busy":"2024-08-05T04:10:48.806238Z","iopub.status.idle":"2024-08-05T04:11:01.862515Z","shell.execute_reply":"2024-08-05T04:11:01.861661Z","shell.execute_reply.started":"2024-08-05T04:10:48.806628Z"},"trusted":true},"outputs":[],"source":["import tensorflow_hub as hub\n","\n","model_name = 'efficientnetv2-b0' #@param {type:'string'}\n","ckpt_type = '1k'   # @param ['21k-ft1k', '1k']\n","hub_type = 'feature-vector' # @param ['classification', 'feature-vector']\n","hub_url, image_size = get_hub_url_and_isize(model_name, ckpt_type, hub_type)\n","\n","tf.keras.backend.clear_session()\n","\n","data_augmentation = keras.Sequential(\n","    [\n","      keras.layers.Resizing(224, 224),\n","      keras.layers.RandomRotation(0.1),\n","      keras.layers.RandomTranslation(0, 0.1),\n","      keras.layers.RandomTranslation(0.1, 0),\n","      keras.layers.RandomZoom(0.1),\n","      keras.layers.RandomCrop(200,200),\n","    ])\n","\n","inputs = keras.Input(shape=(50, 50, 3))\n","x = data_augmentation(inputs)\n","#x = keras.layers.Rescaling(1./255)(x)\n","# Apply input value scaling.\n","x = hub.KerasLayer(hub_url, trainable=True)(x)\n","x = keras.layers.Dropout(0.5)(x)\n","outputs = keras.layers.Dense(800, activation='softmax')(x)\n","model = keras.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9650,"status":"ok","timestamp":1647669053975,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"},"user_tz":-480},"id":"uYHekYJzqfNX","trusted":true},"outputs":[],"source":["# import tensorflow_hub as hub\n","# from tensorflow.keras import layers\n","\n","# tf.keras.backend.clear_session()\n","\n","# data_augmentation = keras.Sequential(\n","#     [\n","#       layers.Resizing(224, 224),\n","#       layers.RandomRotation(0.1),\n","#       layers.RandomTranslation(0, 0.1),\n","#       layers.RandomTranslation(0.1, 0),\n","#       layers.RandomZoom(0.1),\n","#       layers.RandomCrop(200,200),\n","#     ])\n","\n","# hub_url = f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0/feature-vector'\n","# feature_extractor_layer = hub.KerasLayer(hub_url, trainable=True)\n","\n","# # Create the sequential model\n","# model = tf.keras.Sequential([\n","#     # Input layer\n","#     tf.keras.layers.InputLayer(input_shape=(50, 50, 3)),\n","    \n","#     # Rescaling layer\n","#     #tf.keras.layers.Rescaling(1./255),\n","    \n","#     # Data augmentation\n","#     data_augmentation,\n","    \n","#     # Feature extraction layer from TensorFlow Hub\n","#     tf.keras.layers.Lambda(lambda x: feature_extractor_layer(x)),\n","\n","    \n","#     # Dropout layer\n","#     tf.keras.layers.Dropout(0.5),\n","    \n","#     # Output layer\n","#     tf.keras.layers.Dense(800, activation='softmax')\n","# ])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-05T04:11:10.507797Z","iopub.status.busy":"2024-08-05T04:11:10.507160Z","iopub.status.idle":"2024-08-05T04:11:10.540850Z","shell.execute_reply":"2024-08-05T04:11:10.539967Z","shell.execute_reply.started":"2024-08-05T04:11:10.507764Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 50, 50, 3)]       0         \n","                                                                 \n"," sequential (Sequential)     (None, 200, 200, 3)       0         \n","                                                                 \n"," keras_layer (KerasLayer)    (None, 1280)              5919312   \n","                                                                 \n"," dropout (Dropout)           (None, 1280)              0         \n","                                                                 \n"," dense (Dense)               (None, 800)               1024800   \n","                                                                 \n","=================================================================\n","Total params: 6944112 (26.49 MB)\n","Trainable params: 6883504 (26.26 MB)\n","Non-trainable params: 60608 (236.75 KB)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-05T04:11:14.539794Z","iopub.status.busy":"2024-08-05T04:11:14.539389Z","iopub.status.idle":"2024-08-05T05:24:06.815131Z","shell.execute_reply":"2024-08-05T05:24:06.813754Z","shell.execute_reply.started":"2024-08-05T04:11:14.539763Z"},"executionInfo":{"elapsed":5311470,"status":"error","timestamp":1647674419281,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"},"user_tz":-480},"id":"STjf0cnVr_vu","outputId":"c477381c-065c-4853-b9a1-3e98e210a61e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1722831121.111393     119 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["861/861 [==============================] - 147s 105ms/step - loss: 4.1823 - accuracy: 0.2071 - val_loss: 1.8426 - val_accuracy: 0.5394 - lr: 0.1000\n","Epoch 2/50\n","861/861 [==============================] - 86s 100ms/step - loss: 1.1151 - accuracy: 0.7037 - val_loss: 0.4503 - val_accuracy: 0.8799 - lr: 0.1000\n","Epoch 3/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.5578 - accuracy: 0.8451 - val_loss: 0.3470 - val_accuracy: 0.9050 - lr: 0.1000\n","Epoch 4/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.3822 - accuracy: 0.8923 - val_loss: 0.2949 - val_accuracy: 0.9176 - lr: 0.1000\n","Epoch 5/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.2933 - accuracy: 0.9169 - val_loss: 0.2585 - val_accuracy: 0.9268 - lr: 0.1000\n","Epoch 6/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.2339 - accuracy: 0.9338 - val_loss: 0.2280 - val_accuracy: 0.9355 - lr: 0.1000\n","Epoch 7/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.1823 - accuracy: 0.9474 - val_loss: 0.2094 - val_accuracy: 0.9434 - lr: 0.1000\n","Epoch 8/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.1559 - accuracy: 0.9545 - val_loss: 0.1799 - val_accuracy: 0.9486 - lr: 0.1000\n","Epoch 9/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.1439 - accuracy: 0.9588 - val_loss: 0.1837 - val_accuracy: 0.9506 - lr: 0.1000\n","Epoch 10/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.1095 - accuracy: 0.9683 - val_loss: 0.1962 - val_accuracy: 0.9489 - lr: 0.1000\n","Epoch 11/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.1062 - accuracy: 0.9683 - val_loss: 0.1648 - val_accuracy: 0.9564 - lr: 0.1000\n","Epoch 12/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0944 - accuracy: 0.9711 - val_loss: 0.1646 - val_accuracy: 0.9553 - lr: 0.1000\n","Epoch 13/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0850 - accuracy: 0.9750 - val_loss: 0.1471 - val_accuracy: 0.9621 - lr: 0.1000\n","Epoch 14/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0762 - accuracy: 0.9777 - val_loss: 0.1390 - val_accuracy: 0.9598 - lr: 0.1000\n","Epoch 15/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0650 - accuracy: 0.9805 - val_loss: 0.1352 - val_accuracy: 0.9603 - lr: 0.1000\n","Epoch 16/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0589 - accuracy: 0.9830 - val_loss: 0.1772 - val_accuracy: 0.9529 - lr: 0.1000\n","Epoch 17/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 0.1356 - val_accuracy: 0.9621 - lr: 0.1000\n","Epoch 18/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0479 - accuracy: 0.9859 - val_loss: 0.1337 - val_accuracy: 0.9647 - lr: 0.1000\n","Epoch 19/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0809 - accuracy: 0.9792 - val_loss: 0.1532 - val_accuracy: 0.9603 - lr: 0.1000\n","Epoch 20/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0507 - accuracy: 0.9852 - val_loss: 0.1399 - val_accuracy: 0.9644 - lr: 0.1000\n","Epoch 21/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.1398 - val_accuracy: 0.9649 - lr: 0.1000\n","Epoch 22/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0391 - accuracy: 0.9892 - val_loss: 0.1536 - val_accuracy: 0.9586 - lr: 0.1000\n","Epoch 23/50\n","861/861 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9893\n","Epoch 23: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0381 - accuracy: 0.9893 - val_loss: 0.1379 - val_accuracy: 0.9649 - lr: 0.1000\n","Epoch 24/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.1066 - val_accuracy: 0.9728 - lr: 0.0100\n","Epoch 25/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.1007 - val_accuracy: 0.9728 - lr: 0.0100\n","Epoch 26/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.0976 - val_accuracy: 0.9734 - lr: 0.0100\n","Epoch 27/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 0.0970 - val_accuracy: 0.9734 - lr: 0.0100\n","Epoch 28/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0954 - val_accuracy: 0.9743 - lr: 0.0100\n","Epoch 29/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0959 - val_accuracy: 0.9747 - lr: 0.0100\n","Epoch 30/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0941 - val_accuracy: 0.9739 - lr: 0.0100\n","Epoch 31/50\n","861/861 [==============================] - 87s 101ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.0937 - val_accuracy: 0.9746 - lr: 0.0100\n","Epoch 32/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0945 - val_accuracy: 0.9739 - lr: 0.0100\n","Epoch 33/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0947 - val_accuracy: 0.9746 - lr: 0.0100\n","Epoch 34/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0951 - val_accuracy: 0.9744 - lr: 0.0100\n","Epoch 35/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0954 - val_accuracy: 0.9743 - lr: 0.0100\n","Epoch 36/50\n","861/861 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9980\n","Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0961 - val_accuracy: 0.9747 - lr: 0.0100\n","Epoch 37/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0948 - val_accuracy: 0.9749 - lr: 1.0000e-03\n","Epoch 38/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0959 - val_accuracy: 0.9743 - lr: 1.0000e-03\n","Epoch 39/50\n","861/861 [==============================] - 85s 99ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0946 - val_accuracy: 0.9756 - lr: 1.0000e-03\n","Epoch 40/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.0944 - val_accuracy: 0.9753 - lr: 1.0000e-03\n","Epoch 41/50\n","861/861 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9983\n","Epoch 41: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0946 - val_accuracy: 0.9753 - lr: 1.0000e-03\n","Epoch 42/50\n","861/861 [==============================] - 85s 99ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0958 - val_accuracy: 0.9744 - lr: 1.0000e-04\n","Epoch 43/50\n","861/861 [==============================] - 85s 99ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0951 - val_accuracy: 0.9753 - lr: 1.0000e-04\n","Epoch 44/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0942 - val_accuracy: 0.9757 - lr: 1.0000e-04\n","Epoch 45/50\n","861/861 [==============================] - 86s 99ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0950 - val_accuracy: 0.9749 - lr: 1.0000e-04\n","Epoch 46/50\n","861/861 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9976\n","Epoch 46: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0947 - val_accuracy: 0.9747 - lr: 1.0000e-04\n","Epoch 47/50\n","861/861 [==============================] - 86s 100ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0945 - val_accuracy: 0.9744 - lr: 1.0000e-05\n","Epoch 48/50\n","861/861 [==============================] - 85s 99ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.0948 - val_accuracy: 0.9755 - lr: 1.0000e-05\n","Epoch 49/50\n","861/861 [==============================] - 86s 99ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.0948 - val_accuracy: 0.9749 - lr: 1.0000e-05\n","Epoch 50/50\n","861/861 [==============================] - 86s 99ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0947 - val_accuracy: 0.9756 - lr: 1.0000e-05\n"]}],"source":["lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, verbose=1)\n","\n","callbacksa = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"ev2_fine_tuning_0420.keras\",\n","        save_best_only=True,\n","        monitor=\"val_loss\"), lr_scheduler\n","]\n","\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n","              metrics=[\"accuracy\"])\n","\n","history = model.fit(\n","    train_dataset,\n","    epochs=50,\n","    validation_data=validation_dataset,\n","    callbacks=callbacksa)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1091,"status":"ok","timestamp":1647674895304,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"},"user_tz":-480},"id":"5dQ5kjAJD37v","trusted":true},"outputs":[],"source":["model.save(\"my_keras_model_0420.keras\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":3397219,"sourceId":35405,"sourceType":"competition"},{"databundleVersionId":4904169,"modelInstanceId":162,"sourceId":233,"sourceType":"modelInstanceVersion"},{"databundleVersionId":4904171,"modelInstanceId":163,"sourceId":235,"sourceType":"modelInstanceVersion"},{"databundleVersionId":4904116,"modelInstanceId":137,"sourceId":193,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
