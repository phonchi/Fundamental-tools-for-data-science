{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"competition","sourceId":35405,"databundleVersionId":3397219},{"sourceType":"modelInstanceVersion","sourceId":233,"databundleVersionId":4904169,"modelInstanceId":162},{"sourceType":"modelInstanceVersion","sourceId":235,"databundleVersionId":4904171,"modelInstanceId":163},{"sourceType":"modelInstanceVersion","sourceId":193,"databundleVersionId":4904116,"modelInstanceId":137}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{"id":"jRs8qCoF1FIk"}},{"cell_type":"markdown","source":"First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0.","metadata":{"id":"ZB0uE-rI1FIl"}},{"cell_type":"code","source":"# Python ≥3.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Is this notebook running on Colab or Kaggle?\nIS_COLAB = \"google.colab\" in sys.modules\nIS_KAGGLE = \"kaggle_secrets\" in sys.modules\n\n# Scikit-Learn ≥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# TensorFlow ≥2.0 is required\nimport tensorflow as tf\nfrom tensorflow import keras\nassert tf.__version__ >= \"2.0\"\n\nversion_fn = getattr(tf.keras, \"version\", None)\nif version_fn and version_fn().startswith(\"3.\"):\n    import tf_keras as keras\nelse:\n    keras = tf.keras\n\nif not tf.config.list_physical_devices('GPU'):\n    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n    if IS_COLAB:\n        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n    if IS_KAGGLE:\n        print(\"Go to Settings > Accelerator and select GPU.\")\n\n# Common imports\nimport numpy as np\nimport os\nimport pandas as pd\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n# Where to save the figures\nPROJECT_ROOT_DIR = \".\"\nCHAPTER_ID = \"cnn\"\nIMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\nos.makedirs(IMAGES_PATH, exist_ok=True)\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)","metadata":{"id":"Jc9dG1NU1FIm","executionInfo":{"status":"ok","timestamp":1647662906415,"user_tz":-480,"elapsed":3106,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"}},"execution":{"iopub.status.busy":"2024-08-05T04:08:42.097607Z","iopub.execute_input":"2024-08-05T04:08:42.098227Z","iopub.status.idle":"2024-08-05T04:08:56.391508Z","shell.execute_reply.started":"2024-08-05T04:08:42.098195Z","shell.execute_reply":"2024-08-05T04:08:56.390652Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-05 04:08:45.161965: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-05 04:08:45.162076: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-05 04:08:45.287154: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n\nIMAGE_WIDTH=224\nIMAGE_HEIGHT=224\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=1\n\nbatch_size=64\n\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    validation_split=0.2\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n        \"../input/data-science-capstone-project-spring-2022/training_data/training_data\",\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    class_mode='sparse',\n    subset='training',\n    color_mode='grayscale'\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:08:56.393401Z","iopub.execute_input":"2024-08-05T04:08:56.394474Z","iopub.status.idle":"2024-08-05T04:08:58.688682Z","shell.execute_reply.started":"2024-08-05T04:08:56.394432Z","shell.execute_reply":"2024-08-05T04:08:58.687932Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 27785 images belonging to 800 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"A couple utility functions to plot grayscale and RGB images:","metadata":{"id":"nwDbg-7y1FIo"}},{"cell_type":"code","source":"def plot_image(image):\n    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n    plt.axis(\"off\")\n\ndef plot_color_image(image):\n    plt.imshow(image, interpolation=\"nearest\")\n    plt.axis(\"off\")","metadata":{"id":"PvCU2Ic41FIo","executionInfo":{"status":"ok","timestamp":1647662919883,"user_tz":-480,"elapsed":400,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"}},"execution":{"iopub.status.busy":"2024-08-05T04:08:58.689815Z","iopub.execute_input":"2024-08-05T04:08:58.690096Z","iopub.status.idle":"2024-08-05T04:08:58.695262Z","shell.execute_reply.started":"2024-08-05T04:08:58.690073Z","shell.execute_reply":"2024-08-05T04:08:58.694313Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocessing\n\n","metadata":{"id":"sxW4W5wuk93b"}},{"cell_type":"code","source":"from tensorflow.keras.utils import image_dataset_from_directory\n\ntrain_dataset = image_dataset_from_directory(\n    \"../input/data-science-capstone-project-spring-2022/training_data/training_data\",\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=(50, 50),\n    batch_size=32)\nvalidation_dataset = image_dataset_from_directory(\n    \"../input/data-science-capstone-project-spring-2022/training_data/training_data\",\n    validation_split=0.2,\n    seed=1337,\n    subset=\"validation\",\n    image_size=(50, 50),\n    batch_size=32)","metadata":{"id":"mflCzFpBloc8","executionInfo":{"status":"ok","timestamp":1647674555438,"user_tz":-480,"elapsed":2835,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"}},"outputId":"b2cc2ca2-e04f-4c15-b729-cb1e3ab48417","execution":{"iopub.status.busy":"2024-08-05T04:08:58.696789Z","iopub.execute_input":"2024-08-05T04:08:58.697068Z","iopub.status.idle":"2024-08-05T04:09:12.421452Z","shell.execute_reply.started":"2024-08-05T04:08:58.697045Z","shell.execute_reply":"2024-08-05T04:09:12.420561Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 34428 files belonging to 800 classes.\nUsing 27543 files for training.\nFound 34428 files belonging to 800 classes.\nUsing 6885 files for validation.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let’s look at the output of one of these Dataset objects: it yields batches of `180 × 180` RGB images (shape `(32, 180, 180, 3)`) and integer labels (shape `(32,)`). There are 32 samples in each batch (the batch size).","metadata":{"id":"HzNJXxA-ml9G"}},{"cell_type":"code","source":"for data_batch, labels_batch in train_dataset:\n    print(\"data batch shape:\", data_batch.shape)\n    print(\"labels batch shape:\", labels_batch.shape)\n    break","metadata":{"id":"3nVxEzWMmsXA","executionInfo":{"status":"ok","timestamp":1647663870092,"user_tz":-480,"elapsed":294,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"}},"outputId":"c8137c39-762b-46ae-8d68-e1434e8ea5cd","execution":{"iopub.status.busy":"2024-08-05T04:09:12.423205Z","iopub.execute_input":"2024-08-05T04:09:12.423843Z","iopub.status.idle":"2024-08-05T04:09:12.494129Z","shell.execute_reply.started":"2024-08-05T04:09:12.423809Z","shell.execute_reply":"2024-08-05T04:09:12.493256Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"data batch shape: (32, 50, 50, 3)\nlabels batch shape: (32,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Leveraging a pretrained model","metadata":{"id":"iCoc8y_GtY3I"}},{"cell_type":"code","source":"def get_hub_url_and_isize(model_name, ckpt_type, hub_type):\n  if ckpt_type == '1k':\n    ckpt_type = ''  # json doesn't support empty string\n  else:\n    ckpt_type = '-' + ckpt_type  # add '-' as prefix\n  \n  hub_url_map = {\n    'efficientnetv2-b0': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0/{hub_type}',\n    'efficientnetv2-b1': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1/{hub_type}',\n    'efficientnetv2-b2': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2/{hub_type}',\n    'efficientnetv2-b3': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3/{hub_type}',\n    'efficientnetv2-s':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s/{hub_type}',\n    'efficientnetv2-m':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m/{hub_type}',\n    'efficientnetv2-l':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l/{hub_type}',\n\n    'efficientnetv2-b0-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0-21k/{hub_type}',\n    'efficientnetv2-b1-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1-21k/{hub_type}',\n    'efficientnetv2-b2-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2-21k/{hub_type}',\n    'efficientnetv2-b3-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3-21k/{hub_type}',\n    'efficientnetv2-s-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k/{hub_type}',\n    'efficientnetv2-m-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k/{hub_type}',\n    'efficientnetv2-l-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k/{hub_type}',\n    'efficientnetv2-xl-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-xl-21k/{hub_type}',\n\n    'efficientnetv2-b0-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0-21k-ft1k/{hub_type}',\n    'efficientnetv2-b1-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1-21k-ft1k/{hub_type}',\n    'efficientnetv2-b2-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2-21k-ft1k/{hub_type}',\n    'efficientnetv2-b3-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3-21k-ft1k/{hub_type}',\n    'efficientnetv2-s-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k-ft1k/{hub_type}',\n    'efficientnetv2-m-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k-ft1k/{hub_type}',\n    'efficientnetv2-l-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k-ft1k/{hub_type}',\n    'efficientnetv2-xl-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-xl-21k-ft1k/{hub_type}',\n      \n    # efficientnetv1\n    'efficientnet_b0': f'https://tfhub.dev/tensorflow/efficientnet/b0/{hub_type}/1',\n    'efficientnet_b1': f'https://tfhub.dev/tensorflow/efficientnet/b1/{hub_type}/1',\n    'efficientnet_b2': f'https://tfhub.dev/tensorflow/efficientnet/b2/{hub_type}/1',\n    'efficientnet_b3': f'https://tfhub.dev/tensorflow/efficientnet/b3/{hub_type}/1',\n    'efficientnet_b4': f'https://tfhub.dev/tensorflow/efficientnet/b4/{hub_type}/1',\n    'efficientnet_b5': f'https://tfhub.dev/tensorflow/efficientnet/b5/{hub_type}/1',\n    'efficientnet_b6': f'https://tfhub.dev/tensorflow/efficientnet/b6/{hub_type}/1',\n    'efficientnet_b7': f'https://tfhub.dev/tensorflow/efficientnet/b7/{hub_type}/1',\n  }\n  \n  image_size_map = {\n    'efficientnetv2-b0': 224,\n    'efficientnetv2-b1': 240,\n    'efficientnetv2-b2': 260,\n    'efficientnetv2-b3': 300,\n    'efficientnetv2-s':  384,\n    'efficientnetv2-m':  480,\n    'efficientnetv2-l':  480,\n    'efficientnetv2-xl':  512,\n  \n    'efficientnet_b0': 224,\n    'efficientnet_b1': 240,\n    'efficientnet_b2': 260,\n    'efficientnet_b3': 300,\n    'efficientnet_b4': 380,\n    'efficientnet_b5': 456,\n    'efficientnet_b6': 528,\n    'efficientnet_b7': 600,\n  }\n  \n  hub_url = hub_url_map.get(model_name + ckpt_type)\n  image_size = image_size_map.get(model_name, 224)\n  return hub_url, image_size","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:09:26.944808Z","iopub.execute_input":"2024-08-05T04:09:26.945403Z","iopub.status.idle":"2024-08-05T04:09:26.957600Z","shell.execute_reply.started":"2024-08-05T04:09:26.945373Z","shell.execute_reply":"2024-08-05T04:09:26.956637Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\n\nmodel_name = 'efficientnetv2-b0' #@param {type:'string'}\nckpt_type = '1k'   # @param ['21k-ft1k', '1k']\nhub_type = 'feature-vector' # @param ['classification', 'feature-vector']\nhub_url, image_size = get_hub_url_and_isize(model_name, ckpt_type, hub_type)\n\ntf.keras.backend.clear_session()\n\ndata_augmentation = keras.Sequential(\n    [\n      keras.layers.Resizing(224, 224),\n      keras.layers.RandomRotation(0.1),\n      keras.layers.RandomTranslation(0, 0.1),\n      keras.layers.RandomTranslation(0.1, 0),\n      keras.layers.RandomZoom(0.1),\n      keras.layers.RandomCrop(200,200),\n    ])\n\ninputs = keras.Input(shape=(50, 50, 3))\nx = data_augmentation(inputs)\n#x = keras.layers.Rescaling(1./255)(x)\n# Apply input value scaling.\nx = hub.KerasLayer(hub_url, trainable=True)(x)\nx = keras.layers.Dropout(0.5)(x)\noutputs = keras.layers.Dense(800, activation='softmax')(x)\nmodel = keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:10:48.806238Z","iopub.execute_input":"2024-08-05T04:10:48.806660Z","iopub.status.idle":"2024-08-05T04:11:01.862515Z","shell.execute_reply.started":"2024-08-05T04:10:48.806628Z","shell.execute_reply":"2024-08-05T04:11:01.861661Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# import tensorflow_hub as hub\n# from tensorflow.keras import layers\n\n# tf.keras.backend.clear_session()\n\n# data_augmentation = keras.Sequential(\n#     [\n#       layers.Resizing(224, 224),\n#       layers.RandomRotation(0.1),\n#       layers.RandomTranslation(0, 0.1),\n#       layers.RandomTranslation(0.1, 0),\n#       layers.RandomZoom(0.1),\n#       layers.RandomCrop(200,200),\n#     ])\n\n# hub_url = f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0/feature-vector'\n# feature_extractor_layer = hub.KerasLayer(hub_url, trainable=True)\n\n# # Create the sequential model\n# model = tf.keras.Sequential([\n#     # Input layer\n#     tf.keras.layers.InputLayer(input_shape=(50, 50, 3)),\n    \n#     # Rescaling layer\n#     #tf.keras.layers.Rescaling(1./255),\n    \n#     # Data augmentation\n#     data_augmentation,\n    \n#     # Feature extraction layer from TensorFlow Hub\n#     tf.keras.layers.Lambda(lambda x: feature_extractor_layer(x)),\n\n    \n#     # Dropout layer\n#     tf.keras.layers.Dropout(0.5),\n    \n#     # Output layer\n#     tf.keras.layers.Dense(800, activation='softmax')\n# ])","metadata":{"id":"uYHekYJzqfNX","executionInfo":{"status":"ok","timestamp":1647669053975,"user_tz":-480,"elapsed":9650,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:11:10.507160Z","iopub.execute_input":"2024-08-05T04:11:10.507797Z","iopub.status.idle":"2024-08-05T04:11:10.540850Z","shell.execute_reply.started":"2024-08-05T04:11:10.507764Z","shell.execute_reply":"2024-08-05T04:11:10.539967Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 50, 50, 3)]       0         \n                                                                 \n sequential (Sequential)     (None, 200, 200, 3)       0         \n                                                                 \n keras_layer (KerasLayer)    (None, 1280)              5919312   \n                                                                 \n dropout (Dropout)           (None, 1280)              0         \n                                                                 \n dense (Dense)               (None, 800)               1024800   \n                                                                 \n=================================================================\nTotal params: 6944112 (26.49 MB)\nTrainable params: 6883504 (26.26 MB)\nNon-trainable params: 60608 (236.75 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, verbose=1)\n\ncallbacksa = [\n    keras.callbacks.ModelCheckpoint(\n        filepath=\"ev2_fine_tuning_0420.keras\",\n        save_best_only=True,\n        monitor=\"val_loss\"), lr_scheduler\n]\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n              metrics=[\"accuracy\"])\n\nhistory = model.fit(\n    train_dataset,\n    epochs=50,\n    validation_data=validation_dataset,\n    callbacks=callbacksa)","metadata":{"id":"STjf0cnVr_vu","executionInfo":{"status":"error","timestamp":1647674419281,"user_tz":-480,"elapsed":5311470,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"}},"outputId":"c477381c-065c-4853-b9a1-3e98e210a61e","execution":{"iopub.status.busy":"2024-08-05T04:11:14.539389Z","iopub.execute_input":"2024-08-05T04:11:14.539794Z","iopub.status.idle":"2024-08-05T05:24:06.815131Z","shell.execute_reply.started":"2024-08-05T04:11:14.539763Z","shell.execute_reply":"2024-08-05T05:24:06.813754Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1722831121.111393     119 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"861/861 [==============================] - 147s 105ms/step - loss: 4.1823 - accuracy: 0.2071 - val_loss: 1.8426 - val_accuracy: 0.5394 - lr: 0.1000\nEpoch 2/50\n861/861 [==============================] - 86s 100ms/step - loss: 1.1151 - accuracy: 0.7037 - val_loss: 0.4503 - val_accuracy: 0.8799 - lr: 0.1000\nEpoch 3/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.5578 - accuracy: 0.8451 - val_loss: 0.3470 - val_accuracy: 0.9050 - lr: 0.1000\nEpoch 4/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.3822 - accuracy: 0.8923 - val_loss: 0.2949 - val_accuracy: 0.9176 - lr: 0.1000\nEpoch 5/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.2933 - accuracy: 0.9169 - val_loss: 0.2585 - val_accuracy: 0.9268 - lr: 0.1000\nEpoch 6/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.2339 - accuracy: 0.9338 - val_loss: 0.2280 - val_accuracy: 0.9355 - lr: 0.1000\nEpoch 7/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.1823 - accuracy: 0.9474 - val_loss: 0.2094 - val_accuracy: 0.9434 - lr: 0.1000\nEpoch 8/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.1559 - accuracy: 0.9545 - val_loss: 0.1799 - val_accuracy: 0.9486 - lr: 0.1000\nEpoch 9/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.1439 - accuracy: 0.9588 - val_loss: 0.1837 - val_accuracy: 0.9506 - lr: 0.1000\nEpoch 10/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.1095 - accuracy: 0.9683 - val_loss: 0.1962 - val_accuracy: 0.9489 - lr: 0.1000\nEpoch 11/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.1062 - accuracy: 0.9683 - val_loss: 0.1648 - val_accuracy: 0.9564 - lr: 0.1000\nEpoch 12/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0944 - accuracy: 0.9711 - val_loss: 0.1646 - val_accuracy: 0.9553 - lr: 0.1000\nEpoch 13/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0850 - accuracy: 0.9750 - val_loss: 0.1471 - val_accuracy: 0.9621 - lr: 0.1000\nEpoch 14/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0762 - accuracy: 0.9777 - val_loss: 0.1390 - val_accuracy: 0.9598 - lr: 0.1000\nEpoch 15/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0650 - accuracy: 0.9805 - val_loss: 0.1352 - val_accuracy: 0.9603 - lr: 0.1000\nEpoch 16/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0589 - accuracy: 0.9830 - val_loss: 0.1772 - val_accuracy: 0.9529 - lr: 0.1000\nEpoch 17/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 0.1356 - val_accuracy: 0.9621 - lr: 0.1000\nEpoch 18/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0479 - accuracy: 0.9859 - val_loss: 0.1337 - val_accuracy: 0.9647 - lr: 0.1000\nEpoch 19/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0809 - accuracy: 0.9792 - val_loss: 0.1532 - val_accuracy: 0.9603 - lr: 0.1000\nEpoch 20/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0507 - accuracy: 0.9852 - val_loss: 0.1399 - val_accuracy: 0.9644 - lr: 0.1000\nEpoch 21/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.1398 - val_accuracy: 0.9649 - lr: 0.1000\nEpoch 22/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0391 - accuracy: 0.9892 - val_loss: 0.1536 - val_accuracy: 0.9586 - lr: 0.1000\nEpoch 23/50\n861/861 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9893\nEpoch 23: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n861/861 [==============================] - 86s 100ms/step - loss: 0.0381 - accuracy: 0.9893 - val_loss: 0.1379 - val_accuracy: 0.9649 - lr: 0.1000\nEpoch 24/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.1066 - val_accuracy: 0.9728 - lr: 0.0100\nEpoch 25/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.1007 - val_accuracy: 0.9728 - lr: 0.0100\nEpoch 26/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.0976 - val_accuracy: 0.9734 - lr: 0.0100\nEpoch 27/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 0.0970 - val_accuracy: 0.9734 - lr: 0.0100\nEpoch 28/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0954 - val_accuracy: 0.9743 - lr: 0.0100\nEpoch 29/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0959 - val_accuracy: 0.9747 - lr: 0.0100\nEpoch 30/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0941 - val_accuracy: 0.9739 - lr: 0.0100\nEpoch 31/50\n861/861 [==============================] - 87s 101ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.0937 - val_accuracy: 0.9746 - lr: 0.0100\nEpoch 32/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0945 - val_accuracy: 0.9739 - lr: 0.0100\nEpoch 33/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0947 - val_accuracy: 0.9746 - lr: 0.0100\nEpoch 34/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0951 - val_accuracy: 0.9744 - lr: 0.0100\nEpoch 35/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0954 - val_accuracy: 0.9743 - lr: 0.0100\nEpoch 36/50\n861/861 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9980\nEpoch 36: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n861/861 [==============================] - 86s 100ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0961 - val_accuracy: 0.9747 - lr: 0.0100\nEpoch 37/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0948 - val_accuracy: 0.9749 - lr: 1.0000e-03\nEpoch 38/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0959 - val_accuracy: 0.9743 - lr: 1.0000e-03\nEpoch 39/50\n861/861 [==============================] - 85s 99ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0946 - val_accuracy: 0.9756 - lr: 1.0000e-03\nEpoch 40/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.0944 - val_accuracy: 0.9753 - lr: 1.0000e-03\nEpoch 41/50\n861/861 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9983\nEpoch 41: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n861/861 [==============================] - 86s 100ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0946 - val_accuracy: 0.9753 - lr: 1.0000e-03\nEpoch 42/50\n861/861 [==============================] - 85s 99ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0958 - val_accuracy: 0.9744 - lr: 1.0000e-04\nEpoch 43/50\n861/861 [==============================] - 85s 99ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0951 - val_accuracy: 0.9753 - lr: 1.0000e-04\nEpoch 44/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0942 - val_accuracy: 0.9757 - lr: 1.0000e-04\nEpoch 45/50\n861/861 [==============================] - 86s 99ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0950 - val_accuracy: 0.9749 - lr: 1.0000e-04\nEpoch 46/50\n861/861 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9976\nEpoch 46: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n861/861 [==============================] - 86s 100ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0947 - val_accuracy: 0.9747 - lr: 1.0000e-04\nEpoch 47/50\n861/861 [==============================] - 86s 100ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0945 - val_accuracy: 0.9744 - lr: 1.0000e-05\nEpoch 48/50\n861/861 [==============================] - 85s 99ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.0948 - val_accuracy: 0.9755 - lr: 1.0000e-05\nEpoch 49/50\n861/861 [==============================] - 86s 99ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.0948 - val_accuracy: 0.9749 - lr: 1.0000e-05\nEpoch 50/50\n861/861 [==============================] - 86s 99ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0947 - val_accuracy: 0.9756 - lr: 1.0000e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"my_keras_model_0420.keras\")","metadata":{"id":"5dQ5kjAJD37v","executionInfo":{"status":"ok","timestamp":1647674895304,"user_tz":-480,"elapsed":1091,"user":{"displayName":"思齊鍾","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00591983406172857081"}},"trusted":true},"execution_count":null,"outputs":[]}]}